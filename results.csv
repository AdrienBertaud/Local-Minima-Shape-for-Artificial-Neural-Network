optimizer,lr,batch size,num iteration,train loss,train accuracy,test loss,test accuracy,sharpness train,non uniformity trainsharpness testnon uniformity test,non uniformity test,non uniformity train,sharpness test
gd,0.001,10,9,2.280872106552124,20.0,2.308612823486328,0.0,0.4921655654907226,,4.219255657268424,4.937023284690302,-0.4006988406181336
adam,0.001,10,9,0.22548726201057434,90.0,6.196965217590332,20.0,116.73696899414062,,151.68628965318518,162.62936557361041,124.7141571044922
adagrad,0.001,10,9,0.5889165997505188,90.0,3.182180643081665,30.000001907348643,34.103370666503906,,36.59798291594258,40.44313408635095,22.184520721435547
lbfgs,0.001,10,9,1.3600890636444092,60.00000381469727,3.1427955627441406,10.0,13.939557075500488,,11.334198937364645,15.88123685617815,10.945502281188963
gd,0.01,10,9,2.2538557052612305,40.0,2.2994298934936523,10.0,0.2836809754371643,,4.35924767749215,5.218599054586326,0.38541316986083984
adam,0.01,10,9,0.24045757949352264,100.0,11.61192226409912,30.000001907348636,126.2401123046875,,113.72339575561178,193.91454706261726,81.85600280761719
adagrad,0.01,10,9,0.26601868867874146,90.0,4.84956693649292,30.000001907348633,8.176891326904297,,26.903818124710476,14.413861363772808,19.086685180664062
