item =  adagrad
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.1
    weight_decay: 0.01
)
===> Architecture:
FNN(
  (net): Sequential(
    (0): Linear(in_features=784, out_features=500, bias=True)
    (1): ReLU()
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): ReLU()
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): ReLU()
    (6): Linear(in_features=500, out_features=10, bias=True)
  )
)
===> Start training
optimizer.type =  adagrad
1/100, took 0 seconds, train_loss: 9.9e-02, train_acc: 9.60
2/100, took 0 seconds, train_loss: 4.1e+08, train_acc: 9.50
3/100, took 0 seconds, train_loss: 3.7e+08, train_acc: 9.41
4/100, took 0 seconds, train_loss: 3.3e+08, train_acc: 9.51
5/100, took 0 seconds, train_loss: 3.0e+08, train_acc: 9.56
6/100, took 0 seconds, train_loss: 2.7e+08, train_acc: 9.67
7/100, took 0 seconds, train_loss: 2.4e+08, train_acc: 9.78
8/100, took 0 seconds, train_loss: 2.2e+08, train_acc: 9.87
9/100, took 0 seconds, train_loss: 2.0e+08, train_acc: 9.95
10/100, took 0 seconds, train_loss: 1.8e+08, train_acc: 10.03
11/100, took 0 seconds, train_loss: 1.6e+08, train_acc: 10.09
12/100, took 0 seconds, train_loss: 1.4e+08, train_acc: 10.15
13/100, took 0 seconds, train_loss: 1.3e+08, train_acc: 10.21
14/100, took 0 seconds, train_loss: 1.2e+08, train_acc: 10.26
15/100, took 0 seconds, train_loss: 1.0e+08, train_acc: 10.30
16/100, took 0 seconds, train_loss: 9.4e+07, train_acc: 10.26
17/100, took 0 seconds, train_loss: 8.5e+07, train_acc: 10.23
18/100, took 0 seconds, train_loss: 7.6e+07, train_acc: 10.19
19/100, took 0 seconds, train_loss: 6.8e+07, train_acc: 10.16
20/100, took 0 seconds, train_loss: 6.2e+07, train_acc: 10.14
21/100, took 0 seconds, train_loss: 5.5e+07, train_acc: 9.98
22/100, took 0 seconds, train_loss: 5.0e+07, train_acc: 9.85
23/100, took 0 seconds, train_loss: 4.5e+07, train_acc: 9.72
24/100, took 0 seconds, train_loss: 4.0e+07, train_acc: 9.61
25/100, took 0 seconds, train_loss: 3.6e+07, train_acc: 9.57
26/100, took 0 seconds, train_loss: 3.3e+07, train_acc: 9.56
27/100, took 0 seconds, train_loss: 2.9e+07, train_acc: 9.55
28/100, took 0 seconds, train_loss: 2.7e+07, train_acc: 9.67
29/100, took 0 seconds, train_loss: 2.4e+07, train_acc: 9.77
30/100, took 0 seconds, train_loss: 2.1e+07, train_acc: 9.87
31/100, took 0 seconds, train_loss: 1.9e+07, train_acc: 9.95
32/100, took 0 seconds, train_loss: 1.7e+07, train_acc: 9.81
33/100, took 0 seconds, train_loss: 1.6e+07, train_acc: 9.69
34/100, took 0 seconds, train_loss: 1.4e+07, train_acc: 9.87
35/100, took 0 seconds, train_loss: 1.3e+07, train_acc: 9.75
36/100, took 0 seconds, train_loss: 1.1e+07, train_acc: 9.63
37/100, took 0 seconds, train_loss: 1.0e+07, train_acc: 9.53
38/100, took 0 seconds, train_loss: 9.2e+06, train_acc: 9.57
39/100, took 0 seconds, train_loss: 8.3e+06, train_acc: 9.60
40/100, took 0 seconds, train_loss: 7.5e+06, train_acc: 9.63
41/100, took 0 seconds, train_loss: 6.7e+06, train_acc: 9.66
42/100, took 0 seconds, train_loss: 6.1e+06, train_acc: 9.68
43/100, took 0 seconds, train_loss: 5.5e+06, train_acc: 9.70
44/100, took 0 seconds, train_loss: 4.9e+06, train_acc: 9.72
45/100, took 0 seconds, train_loss: 4.4e+06, train_acc: 9.74
46/100, took 0 seconds, train_loss: 4.0e+06, train_acc: 9.76
47/100, took 0 seconds, train_loss: 3.6e+06, train_acc: 9.64
48/100, took 0 seconds, train_loss: 3.2e+06, train_acc: 9.54
49/100, took 0 seconds, train_loss: 2.9e+06, train_acc: 9.44
50/100, took 0 seconds, train_loss: 2.6e+06, train_acc: 9.57
51/100, took 0 seconds, train_loss: 2.4e+06, train_acc: 9.68
52/100, took 0 seconds, train_loss: 2.1e+06, train_acc: 9.78
53/100, took 0 seconds, train_loss: 1.9e+06, train_acc: 9.88
54/100, took 0 seconds, train_loss: 1.7e+06, train_acc: 10.04
55/100, took 0 seconds, train_loss: 1.5e+06, train_acc: 10.18
56/100, took 0 seconds, train_loss: 1.4e+06, train_acc: 10.32
57/100, took 0 seconds, train_loss: 1.2e+06, train_acc: 10.43
58/100, took 0 seconds, train_loss: 1.1e+06, train_acc: 10.25
59/100, took 0 seconds, train_loss: 1.0e+06, train_acc: 10.38
60/100, took 0 seconds, train_loss: 9.1e+05, train_acc: 10.38
61/100, took 0 seconds, train_loss: 8.2e+05, train_acc: 10.20
62/100, took 0 seconds, train_loss: 7.4e+05, train_acc: 10.04
63/100, took 0 seconds, train_loss: 6.6e+05, train_acc: 10.03
64/100, took 0 seconds, train_loss: 6.0e+05, train_acc: 10.01
65/100, took 0 seconds, train_loss: 5.4e+05, train_acc: 10.00
66/100, took 0 seconds, train_loss: 4.8e+05, train_acc: 9.99
67/100, took 0 seconds, train_loss: 4.4e+05, train_acc: 9.98
68/100, took 0 seconds, train_loss: 3.9e+05, train_acc: 9.97
69/100, took 0 seconds, train_loss: 3.5e+05, train_acc: 9.97
70/100, took 0 seconds, train_loss: 3.2e+05, train_acc: 10.12
71/100, took 0 seconds, train_loss: 2.9e+05, train_acc: 10.26
72/100, took 0 seconds, train_loss: 2.6e+05, train_acc: 10.09
73/100, took 0 seconds, train_loss: 2.3e+05, train_acc: 9.94
74/100, took 0 seconds, train_loss: 2.1e+05, train_acc: 10.10
75/100, took 0 seconds, train_loss: 1.9e+05, train_acc: 10.24
76/100, took 0 seconds, train_loss: 1.7e+05, train_acc: 10.37
77/100, took 0 seconds, train_loss: 1.5e+05, train_acc: 10.48
78/100, took 0 seconds, train_loss: 1.4e+05, train_acc: 10.58
79/100, took 0 seconds, train_loss: 1.2e+05, train_acc: 10.67
80/100, took 0 seconds, train_loss: 1.1e+05, train_acc: 10.76
81/100, took 0 seconds, train_loss: 1.0e+05, train_acc: 10.83
82/100, took 0 seconds, train_loss: 9.0e+04, train_acc: 10.61
83/100, took 0 seconds, train_loss: 8.1e+04, train_acc: 10.41
84/100, took 0 seconds, train_loss: 7.3e+04, train_acc: 10.52
85/100, took 0 seconds, train_loss: 6.5e+04, train_acc: 10.45
86/100, took 0 seconds, train_loss: 5.9e+04, train_acc: 10.40
87/100, took 0 seconds, train_loss: 5.3e+04, train_acc: 10.35
88/100, took 0 seconds, train_loss: 4.8e+04, train_acc: 10.46
89/100, took 0 seconds, train_loss: 4.3e+04, train_acc: 10.57
90/100, took 0 seconds, train_loss: 3.9e+04, train_acc: 10.66
91/100, took 0 seconds, train_loss: 3.5e+04, train_acc: 10.74
92/100, took 0 seconds, train_loss: 3.1e+04, train_acc: 10.82
93/100, took 0 seconds, train_loss: 2.8e+04, train_acc: 10.89
94/100, took 0 seconds, train_loss: 2.5e+04, train_acc: 10.95
95/100, took 0 seconds, train_loss: 2.3e+04, train_acc: 11.00
96/100, took 0 seconds, train_loss: 2.1e+04, train_acc: 11.05
97/100, took 0 seconds, train_loss: 1.8e+04, train_acc: 11.10
98/100, took 0 seconds, train_loss: 1.7e+04, train_acc: 11.14
99/100, took 0 seconds, train_loss: 1.5e+04, train_acc: 11.17
100/100, took 0 seconds, train_loss: 1.3e+04, train_acc: 11.21
===> Solution: 
         train loss: 9.00e-02, acc: 11.50
         test loss: 7.10e+03, acc: 10.02
===> Config:
{
  "gpuid": "0,",
  "dataset": "fashionmnist",
  "n_samples": 1000,
  "batch_size": 1000,
  "model_file": "sgd.pkl"
}
===> Config:
{
  "gpuid": "0,",
  "dataset": "fashionmnist",
  "n_samples": 1000,
  "batch_size": 1000,
  "model_file": "sgd.pkl"
}
===> Basic information of the given model: 
         train loss: 9.00e-02, acc: 11.50
         test loss: 7.10e+03, acc: 10.02
===> Compute sharpness:
1-th step takes 0 seconds,       5.76e-05
2-th step takes 0 seconds,       8.68e+01
3-th step takes 0 seconds,       8.70e+01
Sharpness is 8.70e+01

===> Compute non-uniformity:
1-th step takes 30 seconds,      4.53e-06
2-th step takes 30 seconds,      5.80e-01
3-th step takes 30 seconds,      7.77e-01
4-th step takes 30 seconds,      7.70e-01
5-th step takes 30 seconds,      7.76e-01
6-th step takes 30 seconds,      7.60e-01
7-th step takes 30 seconds,      7.82e-01
8-th step takes 30 seconds,      7.84e-01
9-th step takes 31 seconds,      7.95e-01
10-th step takes 31 seconds,     7.73e-01
Non-uniformity is 8.79e-01

item =  lbfgs
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.1
    weight_decay: 0.01
)
===> Architecture:
FNN(
  (net): Sequential(
    (0): Linear(in_features=784, out_features=500, bias=True)
    (1): ReLU()
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): ReLU()
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): ReLU()
    (6): Linear(in_features=500, out_features=10, bias=True)
  )
)
===> Start training
optimizer.type =  lbfgs
1/100, took 0 seconds, train_loss: 5.9e+09, train_acc: 10.20
2/100, took 0 seconds, train_loss: 5.3e+09, train_acc: 11.19
3/100, took 0 seconds, train_loss: 4.7e+09, train_acc: 11.14
4/100, took 0 seconds, train_loss: 4.3e+09, train_acc: 11.03
5/100, took 0 seconds, train_loss: 3.8e+09, train_acc: 10.92
6/100, took 0 seconds, train_loss: 3.5e+09, train_acc: 10.83
7/100, took 0 seconds, train_loss: 3.1e+09, train_acc: 10.90
8/100, took 0 seconds, train_loss: 2.8e+09, train_acc: 10.83
9/100, took 0 seconds, train_loss: 2.5e+09, train_acc: 10.77
10/100, took 0 seconds, train_loss: 2.3e+09, train_acc: 10.61
11/100, took 0 seconds, train_loss: 2.0e+09, train_acc: 10.70
12/100, took 0 seconds, train_loss: 1.8e+09, train_acc: 10.78
13/100, took 0 seconds, train_loss: 1.7e+09, train_acc: 10.85
14/100, took 0 seconds, train_loss: 1.5e+09, train_acc: 10.84
15/100, took 0 seconds, train_loss: 1.3e+09, train_acc: 10.82
16/100, took 0 seconds, train_loss: 1.2e+09, train_acc: 10.76
17/100, took 0 seconds, train_loss: 1.1e+09, train_acc: 10.83
18/100, took 0 seconds, train_loss: 9.8e+08, train_acc: 10.77
19/100, took 0 seconds, train_loss: 8.8e+08, train_acc: 10.71
20/100, took 0 seconds, train_loss: 7.9e+08, train_acc: 10.56
21/100, took 0 seconds, train_loss: 7.1e+08, train_acc: 10.43
22/100, took 0 seconds, train_loss: 6.4e+08, train_acc: 10.53
23/100, took 0 seconds, train_loss: 5.8e+08, train_acc: 10.63
24/100, took 0 seconds, train_loss: 5.2e+08, train_acc: 10.64
25/100, took 0 seconds, train_loss: 4.7e+08, train_acc: 10.64
26/100, took 0 seconds, train_loss: 4.2e+08, train_acc: 10.60
27/100, took 0 seconds, train_loss: 3.8e+08, train_acc: 10.56
28/100, took 0 seconds, train_loss: 3.4e+08, train_acc: 10.65
29/100, took 0 seconds, train_loss: 3.1e+08, train_acc: 10.74
30/100, took 0 seconds, train_loss: 2.8e+08, train_acc: 10.68
31/100, took 0 seconds, train_loss: 2.5e+08, train_acc: 10.77
32/100, took 0 seconds, train_loss: 2.2e+08, train_acc: 10.76
33/100, took 0 seconds, train_loss: 2.0e+08, train_acc: 10.75
34/100, took 0 seconds, train_loss: 1.8e+08, train_acc: 10.83
35/100, took 0 seconds, train_loss: 1.6e+08, train_acc: 10.90
36/100, took 0 seconds, train_loss: 1.5e+08, train_acc: 10.83
37/100, took 0 seconds, train_loss: 1.3e+08, train_acc: 10.89
38/100, took 0 seconds, train_loss: 1.2e+08, train_acc: 10.82
39/100, took 0 seconds, train_loss: 1.1e+08, train_acc: 10.89
40/100, took 0 seconds, train_loss: 9.6e+07, train_acc: 10.95
41/100, took 0 seconds, train_loss: 8.7e+07, train_acc: 11.01
42/100, took 0 seconds, train_loss: 7.8e+07, train_acc: 10.98
43/100, took 0 seconds, train_loss: 7.0e+07, train_acc: 10.95
44/100, took 0 seconds, train_loss: 6.3e+07, train_acc: 11.00
45/100, took 0 seconds, train_loss: 5.7e+07, train_acc: 11.05
46/100, took 0 seconds, train_loss: 5.1e+07, train_acc: 11.10
47/100, took 0 seconds, train_loss: 4.6e+07, train_acc: 11.01
48/100, took 0 seconds, train_loss: 4.1e+07, train_acc: 10.93
49/100, took 0 seconds, train_loss: 3.7e+07, train_acc: 10.98
50/100, took 0 seconds, train_loss: 3.4e+07, train_acc: 11.04
51/100, took 0 seconds, train_loss: 3.0e+07, train_acc: 11.08
52/100, took 0 seconds, train_loss: 2.7e+07, train_acc: 11.12
53/100, took 0 seconds, train_loss: 2.4e+07, train_acc: 11.16
54/100, took 0 seconds, train_loss: 2.2e+07, train_acc: 11.20
55/100, took 0 seconds, train_loss: 2.0e+07, train_acc: 11.23
56/100, took 0 seconds, train_loss: 1.8e+07, train_acc: 11.25
57/100, took 0 seconds, train_loss: 1.6e+07, train_acc: 11.28
58/100, took 0 seconds, train_loss: 1.4e+07, train_acc: 11.30
59/100, took 0 seconds, train_loss: 1.3e+07, train_acc: 11.24
60/100, took 0 seconds, train_loss: 1.2e+07, train_acc: 11.27
61/100, took 0 seconds, train_loss: 1.1e+07, train_acc: 11.29
62/100, took 0 seconds, train_loss: 9.5e+06, train_acc: 11.31
63/100, took 0 seconds, train_loss: 8.5e+06, train_acc: 11.33
64/100, took 0 seconds, train_loss: 7.7e+06, train_acc: 11.35
65/100, took 0 seconds, train_loss: 6.9e+06, train_acc: 11.36
66/100, took 0 seconds, train_loss: 6.2e+06, train_acc: 11.38
67/100, took 0 seconds, train_loss: 5.6e+06, train_acc: 11.39
68/100, took 0 seconds, train_loss: 5.0e+06, train_acc: 11.40
69/100, took 0 seconds, train_loss: 4.5e+06, train_acc: 11.41
70/100, took 0 seconds, train_loss: 4.1e+06, train_acc: 11.34
71/100, took 0 seconds, train_loss: 3.7e+06, train_acc: 11.35
72/100, took 0 seconds, train_loss: 3.3e+06, train_acc: 11.29
73/100, took 0 seconds, train_loss: 3.0e+06, train_acc: 11.31
74/100, took 0 seconds, train_loss: 2.7e+06, train_acc: 11.25
75/100, took 0 seconds, train_loss: 2.4e+06, train_acc: 11.27
76/100, took 0 seconds, train_loss: 2.2e+06, train_acc: 11.22
77/100, took 0 seconds, train_loss: 2.0e+06, train_acc: 11.25
78/100, took 0 seconds, train_loss: 1.8e+06, train_acc: 11.19
79/100, took 0 seconds, train_loss: 1.6e+06, train_acc: 11.22
80/100, took 0 seconds, train_loss: 1.4e+06, train_acc: 11.25
81/100, took 0 seconds, train_loss: 1.3e+06, train_acc: 11.19
82/100, took 0 seconds, train_loss: 1.2e+06, train_acc: 11.23
83/100, took 0 seconds, train_loss: 1.0e+06, train_acc: 11.17
84/100, took 0 seconds, train_loss: 9.3e+05, train_acc: 11.21
85/100, took 0 seconds, train_loss: 8.4e+05, train_acc: 11.23
86/100, took 0 seconds, train_loss: 7.6e+05, train_acc: 11.18
87/100, took 0 seconds, train_loss: 6.8e+05, train_acc: 11.21
88/100, took 0 seconds, train_loss: 6.1e+05, train_acc: 11.24
89/100, took 0 seconds, train_loss: 5.5e+05, train_acc: 11.19
90/100, took 0 seconds, train_loss: 5.0e+05, train_acc: 11.22
91/100, took 0 seconds, train_loss: 4.5e+05, train_acc: 11.17
92/100, took 0 seconds, train_loss: 4.0e+05, train_acc: 11.20
93/100, took 0 seconds, train_loss: 3.6e+05, train_acc: 11.23
94/100, took 0 seconds, train_loss: 3.3e+05, train_acc: 11.18
95/100, took 0 seconds, train_loss: 2.9e+05, train_acc: 11.21
96/100, took 0 seconds, train_loss: 2.6e+05, train_acc: 11.24
97/100, took 0 seconds, train_loss: 2.4e+05, train_acc: 11.18
98/100, took 0 seconds, train_loss: 2.1e+05, train_acc: 11.22
99/100, took 0 seconds, train_loss: 1.9e+05, train_acc: 11.16
100/100, took 0 seconds, train_loss: 1.7e+05, train_acc: 11.20
===> Solution: 
         train loss: 8.99e-02, acc: 11.50
         test loss: 2.60e+03, acc: 10.00
===> Config:
{
  "gpuid": "0,",
  "dataset": "fashionmnist",
  "n_samples": 1000,
  "batch_size": 1000,
  "model_file": "sgd.pkl"
}
===> Config:
{
  "gpuid": "0,",
  "dataset": "fashionmnist",
  "n_samples": 1000,
  "batch_size": 1000,
  "model_file": "sgd.pkl"
}
===> Basic information of the given model: 
         train loss: 8.99e-02, acc: 11.50
         test loss: 2.60e+03, acc: 10.00
===> Compute sharpness:
1-th step takes 0 seconds,       7.07e-06
2-th step takes 0 seconds,       7.01e+00
3-th step takes 0 seconds,       7.37e+00
4-th step takes 0 seconds,       7.39e+00
5-th step takes 0 seconds,       7.39e+00
Sharpness is 7.39e+00

===> Compute non-uniformity:
1-th step takes 30 seconds,      1.16e-06
2-th step takes 30 seconds,      7.88e-02
3-th step takes 28 seconds,      9.20e-02
4-th step takes 28 seconds,      9.90e-02
5-th step takes 28 seconds,      1.05e-01
6-th step takes 28 seconds,      1.09e-01
7-th step takes 28 seconds,      1.12e-01
8-th step takes 28 seconds,      1.14e-01
9-th step takes 28 seconds,      1.15e-01
10-th step takes 28 seconds,     1.16e-01
Non-uniformity is 3.40e-01

item =  adamw
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.1
    weight_decay: 0.01
)
===> Architecture:
FNN(
  (net): Sequential(
    (0): Linear(in_features=784, out_features=500, bias=True)
    (1): ReLU()
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): ReLU()
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): ReLU()
    (6): Linear(in_features=500, out_features=10, bias=True)
  )
)
===> Start training
optimizer.type =  adamw
1/100, took 0 seconds, train_loss: 1.0e-01, train_acc: 10.20
2/100, took 0 seconds, train_loss: 7.6e+08, train_acc: 10.10
3/100, took 0 seconds, train_loss: 6.8e+08, train_acc: 10.01
4/100, took 0 seconds, train_loss: 6.1e+08, train_acc: 9.93
5/100, took 0 seconds, train_loss: 5.5e+08, train_acc: 10.09
6/100, took 0 seconds, train_loss: 5.0e+08, train_acc: 9.94
7/100, took 0 seconds, train_loss: 4.5e+08, train_acc: 9.94
8/100, took 0 seconds, train_loss: 4.0e+08, train_acc: 9.95
9/100, took 0 seconds, train_loss: 3.6e+08, train_acc: 9.95
10/100, took 0 seconds, train_loss: 3.3e+08, train_acc: 9.96
11/100, took 0 seconds, train_loss: 2.9e+08, train_acc: 10.03
12/100, took 0 seconds, train_loss: 2.6e+08, train_acc: 10.07
13/100, took 0 seconds, train_loss: 2.4e+08, train_acc: 10.13
14/100, took 0 seconds, train_loss: 2.1e+08, train_acc: 10.12
15/100, took 0 seconds, train_loss: 1.9e+08, train_acc: 10.13
16/100, took 0 seconds, train_loss: 1.7e+08, train_acc: 10.18
17/100, took 0 seconds, train_loss: 1.6e+08, train_acc: 10.32
18/100, took 0 seconds, train_loss: 1.4e+08, train_acc: 10.43
19/100, took 0 seconds, train_loss: 1.3e+08, train_acc: 10.31
20/100, took 0 seconds, train_loss: 1.1e+08, train_acc: 10.20
21/100, took 0 seconds, train_loss: 1.0e+08, train_acc: 10.33
22/100, took 0 seconds, train_loss: 9.2e+07, train_acc: 10.45
23/100, took 0 seconds, train_loss: 8.3e+07, train_acc: 10.26
24/100, took 0 seconds, train_loss: 7.4e+07, train_acc: 10.10
25/100, took 0 seconds, train_loss: 6.7e+07, train_acc: 10.13
26/100, took 0 seconds, train_loss: 6.0e+07, train_acc: 10.11
27/100, took 0 seconds, train_loss: 5.4e+07, train_acc: 10.10
28/100, took 0 seconds, train_loss: 4.9e+07, train_acc: 10.16
29/100, took 0 seconds, train_loss: 4.4e+07, train_acc: 10.22
30/100, took 0 seconds, train_loss: 4.0e+07, train_acc: 10.34
31/100, took 0 seconds, train_loss: 3.6e+07, train_acc: 10.46
32/100, took 0 seconds, train_loss: 3.2e+07, train_acc: 10.56
33/100, took 0 seconds, train_loss: 2.9e+07, train_acc: 10.43
34/100, took 0 seconds, train_loss: 2.6e+07, train_acc: 10.30
35/100, took 0 seconds, train_loss: 2.3e+07, train_acc: 10.42
36/100, took 0 seconds, train_loss: 2.1e+07, train_acc: 10.38
37/100, took 0 seconds, train_loss: 1.9e+07, train_acc: 10.34
38/100, took 0 seconds, train_loss: 1.7e+07, train_acc: 10.31
39/100, took 0 seconds, train_loss: 1.5e+07, train_acc: 10.30
40/100, took 0 seconds, train_loss: 1.4e+07, train_acc: 10.31
41/100, took 0 seconds, train_loss: 1.2e+07, train_acc: 10.32
42/100, took 0 seconds, train_loss: 1.1e+07, train_acc: 10.29
43/100, took 0 seconds, train_loss: 1.0e+07, train_acc: 10.33
44/100, took 0 seconds, train_loss: 9.0e+06, train_acc: 10.44
45/100, took 0 seconds, train_loss: 8.1e+06, train_acc: 10.55
46/100, took 0 seconds, train_loss: 7.3e+06, train_acc: 10.65
47/100, took 0 seconds, train_loss: 6.6e+06, train_acc: 10.73
48/100, took 0 seconds, train_loss: 5.9e+06, train_acc: 10.68
49/100, took 0 seconds, train_loss: 5.3e+06, train_acc: 10.63
50/100, took 0 seconds, train_loss: 4.8e+06, train_acc: 10.59
51/100, took 0 seconds, train_loss: 4.3e+06, train_acc: 10.68
52/100, took 0 seconds, train_loss: 3.9e+06, train_acc: 10.76
53/100, took 0 seconds, train_loss: 3.5e+06, train_acc: 10.68
54/100, took 0 seconds, train_loss: 3.2e+06, train_acc: 10.62
55/100, took 0 seconds, train_loss: 2.8e+06, train_acc: 10.57
56/100, took 0 seconds, train_loss: 2.6e+06, train_acc: 10.54
57/100, took 0 seconds, train_loss: 2.3e+06, train_acc: 10.48
58/100, took 0 seconds, train_loss: 2.1e+06, train_acc: 10.47
59/100, took 0 seconds, train_loss: 1.9e+06, train_acc: 10.58
60/100, took 0 seconds, train_loss: 1.7e+06, train_acc: 10.67
61/100, took 0 seconds, train_loss: 1.5e+06, train_acc: 10.75
62/100, took 0 seconds, train_loss: 1.4e+06, train_acc: 10.83
63/100, took 0 seconds, train_loss: 1.2e+06, train_acc: 10.76
64/100, took 0 seconds, train_loss: 1.1e+06, train_acc: 10.71
65/100, took 0 seconds, train_loss: 9.9e+05, train_acc: 10.79
66/100, took 0 seconds, train_loss: 8.9e+05, train_acc: 10.86
67/100, took 0 seconds, train_loss: 8.0e+05, train_acc: 10.77
68/100, took 0 seconds, train_loss: 7.2e+05, train_acc: 10.77
69/100, took 0 seconds, train_loss: 6.5e+05, train_acc: 10.73
70/100, took 0 seconds, train_loss: 5.8e+05, train_acc: 10.66
71/100, took 0 seconds, train_loss: 5.3e+05, train_acc: 10.61
72/100, took 0 seconds, train_loss: 4.7e+05, train_acc: 10.70
73/100, took 0 seconds, train_loss: 4.3e+05, train_acc: 10.78
74/100, took 0 seconds, train_loss: 3.8e+05, train_acc: 10.85
75/100, took 0 seconds, train_loss: 3.4e+05, train_acc: 10.92
76/100, took 0 seconds, train_loss: 3.1e+05, train_acc: 10.97
77/100, took 0 seconds, train_loss: 2.8e+05, train_acc: 11.03
78/100, took 0 seconds, train_loss: 2.5e+05, train_acc: 11.07
79/100, took 0 seconds, train_loss: 2.3e+05, train_acc: 11.12
80/100, took 0 seconds, train_loss: 2.0e+05, train_acc: 11.16
81/100, took 0 seconds, train_loss: 1.8e+05, train_acc: 11.19
82/100, took 0 seconds, train_loss: 1.6e+05, train_acc: 11.22
83/100, took 0 seconds, train_loss: 1.5e+05, train_acc: 11.25
84/100, took 0 seconds, train_loss: 1.3e+05, train_acc: 11.27
85/100, took 0 seconds, train_loss: 1.2e+05, train_acc: 11.30
86/100, took 0 seconds, train_loss: 1.1e+05, train_acc: 11.32
87/100, took 0 seconds, train_loss: 9.7e+04, train_acc: 11.34
88/100, took 0 seconds, train_loss: 8.8e+04, train_acc: 11.35
89/100, took 0 seconds, train_loss: 7.9e+04, train_acc: 11.37
90/100, took 0 seconds, train_loss: 7.1e+04, train_acc: 11.38
91/100, took 0 seconds, train_loss: 6.4e+04, train_acc: 11.39
92/100, took 0 seconds, train_loss: 5.8e+04, train_acc: 11.40
93/100, took 0 seconds, train_loss: 5.2e+04, train_acc: 11.41
94/100, took 0 seconds, train_loss: 4.7e+04, train_acc: 11.42
95/100, took 0 seconds, train_loss: 4.2e+04, train_acc: 11.43
96/100, took 0 seconds, train_loss: 3.8e+04, train_acc: 11.44
97/100, took 0 seconds, train_loss: 3.4e+04, train_acc: 11.44
98/100, took 0 seconds, train_loss: 3.1e+04, train_acc: 11.45
99/100, took 0 seconds, train_loss: 2.8e+04, train_acc: 11.45
100/100, took 0 seconds, train_loss: 2.5e+04, train_acc: 11.46
===> Solution: 
         train loss: 9.00e-02, acc: 11.50
         test loss: 1.26e+04, acc: 10.04
===> Config:
{
  "gpuid": "0,",
  "dataset": "fashionmnist",
  "n_samples": 1000,
  "batch_size": 1000,
  "model_file": "sgd.pkl"
}
===> Config:
{
  "gpuid": "0,",
  "dataset": "fashionmnist",
  "n_samples": 1000,
  "batch_size": 1000,
  "model_file": "sgd.pkl"
}
===> Basic information of the given model: 
         train loss: 9.00e-02, acc: 11.50
         test loss: 1.26e+04, acc: 10.04
===> Compute sharpness:
1-th step takes 0 seconds,       1.22e-05
2-th step takes 0 seconds,       7.98e+00
3-th step takes 0 seconds,       1.25e+01
4-th step takes 0 seconds,       1.38e+01
5-th step takes 0 seconds,       1.40e+01
6-th step takes 0 seconds,       1.40e+01
7-th step takes 0 seconds,       1.40e+01
Sharpness is 1.40e+01

===> Compute non-uniformity:
1-th step takes 29 seconds,      2.93e-06
2-th step takes 29 seconds,      1.64e-01
3-th step takes 30 seconds,      3.24e-01
4-th step takes 30 seconds,      3.51e-01
5-th step takes 30 seconds,      3.53e-01
6-th step takes 30 seconds,      3.54e-01
7-th step takes 30 seconds,      3.54e-01
8-th step takes 30 seconds,      3.54e-01
9-th step takes 29 seconds,      3.54e-01
10-th step takes 29 seconds,     3.54e-01
Non-uniformity is 5.95e-01

